{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9WFD4EUQ9DTlzAkYIJ0T7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bo-Ni/Debug_scripts_collection_0/blob/main/Debug_Collagen_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collagen transformer model to predict Tm (small transformer model)\n",
        "\n",
        "#### updated by B. Ni, Apr 17, 2023"
      ],
      "metadata": {
        "id": "OxyRldNRec1G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOCb2AjXeURa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# import torch\n",
        "# print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cmd_line = 'python -c import torch torch.__version__'\n",
        "cmd_line = 'pip3 show torch --version'\n",
        "cmd_out = os.popen(cmd_line).read()\n",
        "print(cmd_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YccnTOgnp4NQ",
        "outputId": "ed585758-980b-44ee-8bb7-21134d87bc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.0.0+cu118\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.9/dist-packages\n",
            "Requires: filelock, jinja2, networkx, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision, triton\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(cmd_out))\n",
        "print(cmd_out[21:33])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUClfhoVsgkt",
        "outputId": "513fd799-a4c1-47b9-b9c6-6846b83b6024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('check pytorch version')\n",
        "if cmd_out[21:33] != '1.11.0+cu113':\n",
        "  cmd_line = 'pip uninstall torch -y'\n",
        "  print(os.popen(cmd_line).read())\n",
        "  cmd_line = 'pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113'\n",
        "  print(os.popen(cmd_line).read())\n",
        "  #\n",
        "  # print(torch.__version__)\n",
        "\n",
        "# '1.0.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmhny3qQime5",
        "outputId": "7aa76428-6c2f-4915-d9bd-013f4c0a3b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check pytorch version\n",
            "Found existing installation: torch 2.0.0+cu118\n",
            "Uninstalling torch-2.0.0+cu118:\n",
            "  Successfully uninstalled torch-2.0.0+cu118\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.11.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp39-cp39-linux_x86_64.whl (1637.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 GB 1.1 MB/s eta 0:00:00\n",
            "Collecting torchvision==0.12.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp39-cp39-linux_x86_64.whl (22.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 22.3/22.3 MB 60.3 MB/s eta 0:00:00\n",
            "Collecting torchaudio==0.11.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp39-cp39-linux_x86_64.whl (2.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 53.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.11.0+cu113) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.12.0+cu113) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.12.0+cu113) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.12.0+cu113) (1.22.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.12.0+cu113) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.12.0+cu113) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.12.0+cu113) (1.26.15)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.1+cu118\n",
            "    Uninstalling torchaudio-2.0.1+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.1+cu118\n",
            "Successfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmd_line = 'pip3 show torch --version'\n",
        "cmd_out = os.popen(cmd_line).read()\n",
        "print(cmd_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Ls-SpLtlzP",
        "outputId": "219b305d-19d9-4c3f-ae16-a48890add7a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 1.11.0+cu113\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.9/dist-packages\n",
            "Requires: typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision, triton\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "qrhFI-31gQBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add packages\n",
        "\n",
        "try:\n",
        "  print('\\033[1;32m c. on einops...')\n",
        "  from einops import rearrange, repeat, reduce\n",
        "except ImportError as e:\n",
        "  print(os.popen('pip install einops').read()) \n",
        "\n",
        "try:\n",
        "  # print('\\033[1;32m c. on einops...')\n",
        "  from x_transformers import XTransformer,ContinuousTransformerWrapper, Decoder, Encoder\n",
        "except ImportError as e:\n",
        "  print(os.popen('pip install x_transformers==0.28.0').read()) \n",
        "  # print(os.popen('pip install x_transformers').read()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfCZaCxvgZsF",
        "outputId": "c733f48a-fa7a-4cf9-8737-2106bff52c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32m c. on einops...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.6/41.6 kB 2.3 MB/s eta 0:00:00\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting x_transformers==0.28.0\n",
            "  Downloading x_transformers-0.28.0-py3-none-any.whl (15 kB)\n",
            "Collecting entmax\n",
            "  Downloading entmax-1.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.9/dist-packages (from x_transformers==0.28.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.9/dist-packages (from x_transformers==0.28.0) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6->x_transformers==0.28.0) (4.5.0)\n",
            "Installing collected packages: entmax, x_transformers\n",
            "Successfully installed entmax-1.1 x_transformers-0.28.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os,sys\n",
        "import math\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "import cv2\n",
        "import PIL \n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "import pickle\n",
        "import torchvision.utils as vutils\n",
        "import torch\n",
        " \n",
        "import torchvision\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " \n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
        "\n",
        "print(\"Torch version:\", torch.__version__) \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "import seaborn as sns\n",
        "import pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4K_oeUnedfe",
        "outputId": "b86f36ab-0375-4cf4-80df-ee3a9c183ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import pi, log\n",
        "import time\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "RD3u3Oi5egk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://www.dropbox.com/s/8oiyjvgn3nofkkh/model_IO_REGRESS_1290.pth?dl=0 -O model_IO_REGRESS_1290.pth\n",
        "# !wget https://www.dropbox.com/s/60ximulejl6fq4b/tokenizer_and_qt.pickle?dl=0 -O tokenizer_and_qt.pickle\n",
        "\n",
        "checkpoint_file = \"model_IO_REGRESS_1290.pth\"\n",
        "file_exists = os.path.exists(checkpoint_file)\n",
        "if not (file_exists):\n",
        "  # download things\n",
        "  print(os.popen(\"wget https://www.dropbox.com/s/8oiyjvgn3nofkkh/model_IO_REGRESS_1290.pth?dl=0 -O model_IO_REGRESS_1290.pth\").read())\n",
        "\n",
        "tokenizer_file = \"tokenizer_and_qt.pickle\"\n",
        "file_exists = os.path.exists(tokenizer_file)\n",
        "if not (file_exists):\n",
        "  # download things\n",
        "  print(os.popen(\"wget https://www.dropbox.com/s/60ximulejl6fq4b/tokenizer_and_qt.pickle?dl=0 -O tokenizer_and_qt.pickle\").read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8zeCgG_hBm4",
        "outputId": "3af6302c-a142-44c5-c1de-31790571f5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#source: https://github.com/lucidrains/x-transformers\n",
        "#!pip install x_transformers==0.28.0\n",
        "\n",
        "from x_transformers import XTransformer,ContinuousTransformerWrapper, Decoder, Encoder"
      ],
      "metadata": {
        "id": "nZChlu-xhiuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                                  else \"cpu\")\n"
      ],
      "metadata": {
        "id": "AzfKXl-7iEh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision.io import read_image\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "to_pil = transforms.ToPILImage()"
      ],
      "metadata": {
        "id": "yOpngCTFibEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens_=25 \n",
        "max_length = 64"
      ],
      "metadata": {
        "id": "fy1-V42AieQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim_x = 8  # for x\n",
        "embed_dim = 8 #for position \n",
        "embed_dim_conv=8  #for conv\n",
        "kernel_siz = 3\n",
        "\n",
        "latent_dim_ =32\n",
        "\n",
        "nconv=2 #number of convs for input\n",
        "\n",
        "class MyTotal_pos(nn.Module):\n",
        "    def __init__(self ):\n",
        "        super(MyTotal_pos, self).__init__()\n",
        "        \n",
        "        self.mSig = nn.Sigmoid()\n",
        "        self.queries_dim_=embed_dim  + embed_dim_x #dim_\n",
        "         \n",
        "         \n",
        "        \n",
        "        self.emb_data = nn.Embedding(num_tokens_, embed_dim_x*1,  padding_idx=0)\n",
        "        self.pos_emb_x = nn.Embedding(max_length, embed_dim*1)\n",
        "        \n",
        "        self.fc_x1 = nn.Linear(   embed_dim_x, embed_dim_x )  # INPUT DIM (last), OUTPUT DIM, last\n",
        "        \n",
        "        self.fc1 = nn.Linear( max_length,  1)  # INPUT DIM (last), OUTPUT DIM, last\n",
        "        self.fc2 = nn.Linear( max_length,  1)  # INPUT DIM (last), OUTPUT DIM, last\n",
        "        self.fc3 = nn.Linear( max_length,  1)  # INPUT DIM (last), OUTPUT DIM, last\n",
        "        \n",
        "        self.BatchNorm_1 = nn.BatchNorm1d(max_length)\n",
        "        self.fc_last = nn.Linear( self.queries_dim_,  1)  \n",
        "        self.fc_last_2 = nn.Linear( max_length,  1)  \n",
        "        \n",
        "        self.convs=[]\n",
        "        self.skips_cons=[]\n",
        "        icgg=0\n",
        "        for _ in range(nconv):\n",
        "            if icgg==0: #first one opertes on 3 channels only\n",
        "                self.convs.append(nn.Conv1d(in_channels=embed_dim_x, out_channels=embed_dim_conv, kernel_size=3, stride=1, \\\n",
        "                                        padding='same'))#.cuda())\n",
        "                 \n",
        "            if icgg>0:\n",
        "                self.convs.append(nn.Conv1d(in_channels=embed_dim_x, out_channels=embed_dim_conv, kernel_size=3, stride=1, \\\n",
        "                                        padding='same'))#.cuda())\n",
        "            icgg=icgg+1\n",
        "             \n",
        "        self.convs = nn.ModuleList(self.convs)\n",
        "        \n",
        "        self.pos_matrix_i = torch.zeros (max_length, dtype=torch.long)\n",
        "        \n",
        "        for i in range (max_length):\n",
        "            \n",
        "                self.pos_matrix_i [i]=i\n",
        "            \n",
        " \n",
        "        self.modelB = ContinuousTransformerWrapper(\n",
        "            dim_in = self.queries_dim_,\n",
        "            dim_out = self.queries_dim_,\n",
        "            max_seq_len = max_length,\n",
        "            attn_layers = Encoder(\n",
        "                dim = self.queries_dim_,\n",
        "                depth = 3,\n",
        "               heads = 8\n",
        "               ))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        n=self.queries_dim_\n",
        "         \n",
        "        x = self.emb_data( x)\n",
        "       \n",
        "        x = torch.squeeze(x, 1)\n",
        "        \n",
        "        x= self.BatchNorm_1(x)\n",
        "        \n",
        "        pos_matrix_i_=self.pos_matrix_i.repeat(x.shape[0], 1, 1).to(device=device) \n",
        "        \n",
        "        \n",
        "        pos_emb_x = self.pos_emb_x( pos_matrix_i_)\n",
        "        pos_emb_x = torch.squeeze(pos_emb_x, 1)\n",
        "        \n",
        "        self.skips_cons=[]\n",
        "         \n",
        "        convcount=0\n",
        "        for  encoder in self.convs:\n",
        "            if convcount==0:\n",
        "                x_cc=torch.permute(x, (0,2,1)  )\n",
        "            else:\n",
        "                x_cc=torch.permute(x_cc, (0,2,1)  )\n",
        "            \n",
        "            x_cc =  encoder.to(device=device)(x_cc)\n",
        "            x_cc=torch.permute(x_cc, (0,2,1)  )\n",
        "           \n",
        "            self.skips_cons.append(x_cc)\n",
        "            convcount=  convcount+1\n",
        "            \n",
        "        \n",
        "        for skip in self.skips_cons[:-1]:\n",
        "            x_cc = torch.cat((x_cc, skip), axis=2)\n",
        "\n",
        "        \n",
        "        x= torch.cat( (x,    pos_emb_x), 2)\n",
        "             \n",
        "        x2 = self.modelB(x) #, queries = query1)\n",
        "        \n",
        "        x2=self.fc_last (x2)\n",
        "        x2=torch.permute(x2, (0,2,1)  )\n",
        "        x2=self.fc_last_2 (x2)\n",
        "        #x2=self.mSig(x2)\n",
        "        \n",
        "        return x2\n",
        " \n",
        "model = MyTotal_pos(  )"
      ],
      "metadata": {
        "id": "5QeuucxLigKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "pytorch_total_params_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print (\"Total parameters: \", pytorch_total_params,\" trainable parameters: \", pytorch_total_params_trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfMIJdSaihuo",
        "outputId": "d17f2fe3-bfe1-4e01-a9b4-afe5c550666e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters:  108069  trainable parameters:  108069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading\n",
        "with open('tokenizer_and_qt.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "    qt = pickle.load(handle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPT6PraBij5Y",
        "outputId": "329695fd-2b89-4865-cf8b-8e3ad55e474a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General inference for a given sequence"
      ],
      "metadata": {
        "id": "xXG0RMzWitjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "def SS_predictor(model,tokenizer,seq,max_length, qt=None):\n",
        "    model.eval()\n",
        "    prot_1 = tokenizer.texts_to_sequences([seq[:]])\n",
        "    prot_1 = sequence.pad_sequences(prot_1, maxlen=max_length, padding='post' )\n",
        "    prot_1 = torch.from_numpy(prot_1).to(device)\n",
        "    \n",
        "    #print(prot_1.shape)\n",
        "    prot_tm=model(prot_1) \n",
        "    if qt : #inverse scale if PRESENT\n",
        "        temp_=prot_tm.cpu().detach().numpy() \n",
        "        temp_=np.squeeze(temp_, 2)\n",
        "        prot_tm=qt.inverse_transform(temp_)\n",
        "    \n",
        "    prot_tm=np.squeeze(prot_tm)\n",
        "    \n",
        "    return prot_tm "
      ],
      "metadata": {
        "id": "hn2D5gEFisuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model if not loaded yet\n",
        "name='./model_IO_REGRESS_1290.pth'\n",
        "model = torch.load(name).to(device)"
      ],
      "metadata": {
        "id": "b14K1dFtixPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tm=SS_predictor (model, tokenizer, 'GPOGPOGPOGPOGPQGPGGPPGPOGPOGPOGPOGPO', max_length, qt)\n",
        "print (Tm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xBaMq1cizAK",
        "outputId": "6ea38f0e-f83c-4194-e50c-8e268f5e792b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62.486595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ObyK6VWVjJ7T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}